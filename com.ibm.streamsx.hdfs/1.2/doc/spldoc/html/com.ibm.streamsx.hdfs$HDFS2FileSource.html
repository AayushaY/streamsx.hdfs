<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en-us" lang="en-us">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="copyright" content="(C) Copyright 2005"/>
<meta name="DC.rights.owner" content="(C) Copyright 2005"/>
<meta name="DC.Type" content="reference"/>
<meta name="DC.Title" content="com.ibm.streamsx.hdfs::HDFS2FileSource"/>
<meta name="DC.Format" content="XHTML"/>
<meta name="DC.Identifier" content="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource"/>
<link rel="stylesheet" type="text/css" href="../html/commonltr.css"/>
<link rel="stylesheet" type="text/css" href="../html/spldoc.css"/>
<title>com.ibm.streamsx.hdfs::HDFS2FileSource</title>
</head>
<body id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource">


<h1 class="title topictitle1">com.ibm.streamsx.hdfs::HDFS2FileSource</h1>

<div class="body refbody">
<div class="section">
<p class="p">
<a class="xref" href="toolkit.html" title="com.ibm.streamsx.hdfs">
com.ibm.streamsx.hdfs
</a>
-&gt; <a class="xref" href="com.ibm.streamsx.hdfs$.html">com.ibm.streamsx.hdfs</a>-&gt; HDFS2FileSource</p>

</div>

<div class="section">

<p class="p">The HDFS2FileSource operator reads files from a Hadoop Distributed File System (HDFS). 
</p>

<p class="p">The operator opens a file on HDFS and sends out its contents in tuple format on its output port.   
</p>

<p class="p">If the optional input port is not specified, the operator reads the HDFS file that is specified in the <strong class="ph b">file</strong> parameter and  provides the file contents on the output port.  If the optional input port is configured, the operator reads the files that are  named by the attribute in the tuples that arrive on its input port and places a punctuation marker between each file. 
</p>

<p class="p"><strong class="ph b">Exceptions</strong> 
</p>

<p class="p">The HDFS2FileSource operator terminates in the following cases: 
</p>

<ul class="ul">
<li class="li"> The operator cannot connect to HDFS. </li>

<li class="li"> The file cannot be opened. </li>

<li class="li"> The file does not exist. </li>

<li class="li"> The file becomes unreadable. </li>

<li class="li"> A tuple cannot be created from the file contents (such as a problem with the file format). </li>

</ul>

<p class="p"> <strong class="ph b">Examples</strong> 
</p>

<div class="p">In the following example, the HDFSDirectoryScan operator scans the HDFS directory every two seconds and the HDFS2FileSource operator reads the files output by the HDFSDirectoryScan operator. 
<pre class="pre codeblock">
   
/*
* HDFSDirectoryScan operator scans /user/myser/ directory from HDFS every 2.0 seconds
* Overrides the URI in the fs.defaultFS option from core-site.xml file
*/
(stream&lt;rstring filename&gt; Files) as HDFSDirectoryScan_1 = HDFSDirectoryScan(){
  		param
   			directory     : "/user/myuser/";
   			hdfsUri:"hdfs : //hdfsServer:1883";
   			sleepTime     : 2.0;
}
// HDFS2FileSource operator reads from files discovered by HDFSDirectoryScan operator
(stream&lt;rstring data&gt; FileContent) as HDFS2FileSource_2 =	HDFS2FileSource(Files){
  		param
		hdfsUri:"hdfs://hdfsSever:1883"; 
   	}
</pre>


</div>

<p class="p"> The following example shows how the operator accesses GPFS remotely and reads a file that is specified by the <strong class="ph b">file</strong> parameter: 
</p>

<div class="p">
<pre class="pre codeblock">
(stream&lt;rstring data&gt; FileContent) as HDFS2FileSource_2 = HDFS2FileSource(){
  		param
		hdfsUri:"webhdfs://bigInsightSever:1883"; 
   			file   :"/user/myser/myfile.txt"; 
   			
</pre>


</div>

<p class="p"> 
</p>

</div>

<div class="section splprimop">
<object type="image/svg+xml" data="../image/com.ibm.streamsx.hdfs$HDFS2FileSource.svg" width="672" height="112">
<span>Primitive operator image not displayed. Problem loading file: ../image/com.ibm.streamsx.hdfs$HDFS2FileSource.svg
</span>
</object>
</div>

<div class="section"><h2 class="title sectiontitle splhead-1">Summary</h2>

<dl class="dl" compact="compact">
 
  <dt class="dt dlterm">Ports</dt>

  <dd class="dd">This operator has 1 input port and 1 output port.</dd>

 
 
  <dt class="dt dlterm">Windowing</dt>

  <dd class="dd">This operator does not accept any windowing configurations.</dd>

 
 
  <dt class="dt dlterm">Parameters</dt>

  <dd class="dd">This operator supports 10 parameters. (<tt class="ph tt">file, initDelay, hdfsUri, hdfsUser, authPrincipal, authKeytab, credFile, configPath, encoding, blockSize</tt>)
</dd>

 
 
  <dt class="dt dlterm">Metrics</dt>

  <dd class="dd">This operator reports  1 metrics.</dd>

 
</dl>
</div>

<div class="section"><h2 class="title sectiontitle splhead-1">Properties</h2>

<dl class="dl" compact="compact">
 
  <dt class="dt dlterm">Implementation</dt>

  <dd class="dd">Java</dd>

 
</dl>

</div>

<div class="section">
<p class="p splhead-1"><strong class="ph b"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__input_port_set">Input Ports</a></strong></p>
<dl class="dl">
  
   <dt class="dt dlterm">Ports (0)</dt>

   <dd class="dd">

<p class="p">The HDFS2FileSource operator has one optional input port. If an input port is specified, the operator expects an input tuple with a single attribute of type rstring. The input tuples contain the file names that the operator opens for reading. The input port is non-mutating.
</p>
   </dd>

  
    
      <dt class="dt dlterm">Windowing</dt>

      <dd class="dd">
      </dd>

    
    
      <dt class="dt dlterm">Properties</dt>

      <dd class="dd">
   <ul class="sl simple">
     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__input_port_set__optional">Optional</a>: true
     </li>

   </ul>

   <ul class="sl simple">
     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__input_port_set__controlport">ControlPort</a>: false
</li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__input_port_set__windowingmode">WindowingMode</a>: NonWindowed
</li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__input_port_set__windowpunctuationinputmode">WindowPunctuationInputMode</a>: Oblivious
</li>

   </ul>

      </dd>

    
</dl>

</div>

<div class="section">
<p class="p splhead-1"><strong class="ph b"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__output_port_set">Output Ports</a></strong></p>
<dl class="dl">
  
     <dt class="dt dlterm">Assignments</dt>

       <dd class="dd">Java operators do not support output assignments.
       </dd>

  
</dl>

<dl class="dl">
  
   <dt class="dt dlterm">Ports (0)</dt>

   <dd class="dd">

<p class="p">The HDFS2FileSource operator has one output port.  The tuples on the output port contain the data that is read from the files. The operator includes a punctuation marker at the conclusion of each file. The output port is mutating.
</p>

<p class="p"/>

   <dl class="dl">
    
      <dt class="dt dlterm">Properties</dt>

      <dd class="dd">
   <ul class="sl simple">
     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__output_port_set__optional">Optional</a>: false
     </li>

   </ul>

   <ul class="sl simple">
     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__output_port_set__windowpunctuationoutputmode">WindowPunctuationOutputMode</a>: Generating
     </li>

   </ul>

      </dd>

    
   </dl>

   <p class="p"/>

   </dd>

  
</dl>

</div>

<div class="section">
<p class="p splhead-1"><strong class="ph b"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters">Parameters</a></strong></p>

<dl class="dl">

<dt class="dt dlterm" id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource__parameter_file"><tt class="ph tt">file</tt></dt>

<dd class="dd">
<p class="p">This parameter specifies the name of file that the operator opens and reads.  This parameter must be specified when the optional input port is not configured. If the optional input port is used and the file name is specified, the operator generates an error.
</p>
<dl class="dl">

 <dt class="dt dlterm">Properties </dt>

 <dd class="dd">
  <ul class="sl simple">
  <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__type">Type</a>: rstring
  </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__cardinality">Cardinality</a>: 1
     </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__optional">Optional</a>: true
     </li>

  </ul>

 </dd>


</dl>

</dd>



<dt class="dt dlterm" id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource__parameter_initDelay"><tt class="ph tt">initDelay</tt></dt>

<dd class="dd">
<p class="p">This parameter specifies the time to wait in seconds before the operator reads the first file.   The default value is <tt class="ph tt">0</tt>.
</p>
<dl class="dl">

 <dt class="dt dlterm">Properties </dt>

 <dd class="dd">
  <ul class="sl simple">
  <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__type">Type</a>: float64
  </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__cardinality">Cardinality</a>: 1
     </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__optional">Optional</a>: true
     </li>

  </ul>

 </dd>


</dl>

</dd>



<dt class="dt dlterm" id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource__parameter_hdfsUri"><tt class="ph tt">hdfsUri</tt></dt>

<dd class="dd">
<p class="p">This parameter specifies the uniform resource identifier (URI) that you can use to connect to  the HDFS file system.  The URI has the following format: 
</p>

<ul class="ul">
<li class="li"> To access HDFS locally or remotely, use `hdfs://*hdfshost*:*hdfsport* </li>

<li class="li"> To access GPFS locally, use <tt class="ph tt">gpfs:///</tt>. </li>

<li class="li"> To access GPFS remotely, use `webhdfs://*hdfshost*:*webhdfsport* </li>

</ul>

<p class="p"> If this parameter is not specified, the operator expects that the HDFS URI is specified as the <tt class="ph tt">fs.defaultFS</tt> or  <tt class="ph tt">fs.default.name</tt> property in the <tt class="ph tt">core-site.xml</tt> HDFS configuration file.  The operator expects the <tt class="ph tt">core-site.xml</tt>  file to be in <tt class="ph tt">$HADOOP_HOME/../hadoop-conf</tt> or <tt class="ph tt">$HADOOP_HOME/etc/hadoop</tt>. 
</p>
<dl class="dl">

 <dt class="dt dlterm">Properties </dt>

 <dd class="dd">
  <ul class="sl simple">
  <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__type">Type</a>: rstring
  </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__cardinality">Cardinality</a>: 1
     </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__optional">Optional</a>: true
     </li>

  </ul>

 </dd>


</dl>

</dd>



<dt class="dt dlterm" id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource__parameter_hdfsUser"><tt class="ph tt">hdfsUser</tt></dt>

<dd class="dd">
<p class="p">This parameter specifies the user ID to use when you connect to the HDFS file system.   If this parameter is not specified, the operator uses the instance owner to connect to the HDFS file system. 
</p>

<p class="p">When you use Kerberos authentication, the operator authenticates with the Hadoop file system as the instance owner by using the  values that are specified in the <strong class="ph b">authPrincipal</strong> and <strong class="ph b">authKeytab</strong> parameters.  After successful authentication, the operator uses the user ID that is specified by the <strong class="ph b">hdfsUser</strong> parameter to perform all other operations on the file system. 
</p>

<p class="p"><strong class="ph b">NOTE:</strong> When using Kerberos authentication, the InfoSphere Streams instance owner must have super user privileges on HDFS or GPFS to perform operations as the user that is specified by the <strong class="ph b">hdfsUser</strong> parameter.
</p>
<dl class="dl">

 <dt class="dt dlterm">Properties </dt>

 <dd class="dd">
  <ul class="sl simple">
  <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__type">Type</a>: rstring
  </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__cardinality">Cardinality</a>: 1
     </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__optional">Optional</a>: true
     </li>

  </ul>

 </dd>


</dl>

</dd>



<dt class="dt dlterm" id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource__parameter_authPrincipal"><tt class="ph tt">authPrincipal</tt></dt>

<dd class="dd">
<p class="p">This parameter specifies the Kerberos principal that you use for authentication. This value is set to the principal that is created for the InfoSphere Streams instance owner. You must specify this parameter if you want to use Kerberos authentication.
</p>
<dl class="dl">

 <dt class="dt dlterm">Properties </dt>

 <dd class="dd">
  <ul class="sl simple">
  <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__type">Type</a>: rstring
  </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__cardinality">Cardinality</a>: 1
     </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__optional">Optional</a>: true
     </li>

  </ul>

 </dd>


</dl>

</dd>



<dt class="dt dlterm" id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource__parameter_authKeytab"><tt class="ph tt">authKeytab</tt></dt>

<dd class="dd">
<p class="p">This parameter specifies the file that contains the encrypted keys for the user that is specified by the <strong class="ph b">authPrincipal</strong> parameter.  The operator uses this keytab file to authenticate the user. The keytab file is generated by the administrator.  You must specify this parameter to use Kerberos authentication.
</p>
<dl class="dl">

 <dt class="dt dlterm">Properties </dt>

 <dd class="dd">
  <ul class="sl simple">
  <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__type">Type</a>: rstring
  </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__cardinality">Cardinality</a>: 1
     </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__optional">Optional</a>: true
     </li>

  </ul>

 </dd>


</dl>

</dd>



<dt class="dt dlterm" id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource__parameter_credFile"><tt class="ph tt">credFile</tt></dt>

<dd class="dd">
<p class="p">This parameter specifies a file that contains login credentials. The credentials are used to connect to GPFS remotely by using the <tt class="ph tt">webhdfs://*hdfshost*:*webhdfsport*</tt> schema.  The credentials file must contain information about how to authenticate with IBM InfoSphere BigInsights when using the webhdfs schema.  For example, the file must contain the  user name and password for an IBM InfoSphere BigInsights user.
</p>
<dl class="dl">

 <dt class="dt dlterm">Properties </dt>

 <dd class="dd">
  <ul class="sl simple">
  <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__type">Type</a>: rstring
  </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__cardinality">Cardinality</a>: 1
     </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__optional">Optional</a>: true
     </li>

  </ul>

 </dd>


</dl>

</dd>



<dt class="dt dlterm" id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource__parameter_configPath"><tt class="ph tt">configPath</tt></dt>

<dd class="dd">
<p class="p">This parameter specifies the absolute path to the directory that contains the <tt class="ph tt">core-site.xml</tt> file, which is an HDFS configuration file. If this parameter is not specified, the operator searches the default location for the <tt class="ph tt">core-site.xml</tt> file.
</p>
<dl class="dl">

 <dt class="dt dlterm">Properties </dt>

 <dd class="dd">
  <ul class="sl simple">
  <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__type">Type</a>: rstring
  </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__cardinality">Cardinality</a>: 1
     </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__optional">Optional</a>: true
     </li>

  </ul>

 </dd>


</dl>

</dd>



<dt class="dt dlterm" id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource__parameter_encoding"><tt class="ph tt">encoding</tt></dt>

<dd class="dd">
<p class="p">This parameter specifies the encoding to use when reading files. The default value is <tt class="ph tt">UTF-8</tt>.
</p>
<dl class="dl">

 <dt class="dt dlterm">Properties </dt>

 <dd class="dd">
  <ul class="sl simple">
  <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__type">Type</a>: rstring
  </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__cardinality">Cardinality</a>: 1
     </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__optional">Optional</a>: true
     </li>

  </ul>

 </dd>


</dl>

</dd>



<dt class="dt dlterm" id="spldoc_operator__com.ibm.streamsx.hdfs__HDFS2FileSource__parameter_blockSize"><tt class="ph tt">blockSize</tt></dt>

<dd class="dd">
<p class="p">The maximum number of bytes to read into a blob.  Only applicable if reading in binary mode.
</p>
<dl class="dl">

 <dt class="dt dlterm">Properties </dt>

 <dd class="dd">
  <ul class="sl simple">
  <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__type">Type</a>: int32
  </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__cardinality">Cardinality</a>: 1
     </li>

     <li class="sli"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__parameters__parameter__optional">Optional</a>: true
     </li>

  </ul>

 </dd>


</dl>

</dd>


</dl>

</div>

<div class="section">
<p class="p splhead-1"><strong class="ph b"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__context__codetemplate">Code Templates</a></strong></p>
  <dl class="dl">
    
     <dt class="dt dlterm">HDFS2FileSource</dt>

     <dd class="dd">
       <pre class="pre codeblock">
stream&lt;${streamType}&gt; ${streamName} = HDFS2FileSource() {
                param
                file : "${filename}";
                }
      </pre>

     <p class="p"/>

     </dd>

    
    
     <dt class="dt dlterm">HDFS2FileSource with hdfsUser and hdfsUri</dt>

     <dd class="dd">
       <pre class="pre codeblock">
stream&lt;${streamType}&gt; ${streamName} = HDFS2FileSource() {
                param
                file: "${filename}";
                hdfsUser: "${hdfsUser}";
                hdfsUri: "${hdfsUri}";
                }
      </pre>

     <p class="p"/>

     </dd>

    
  </dl>

</div>

<div class="section">
<p class="p splhead-1"><strong class="ph b"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__context__metrics">Metrics</a></strong></p>
<dl class="dl">
  
    <dt class="dt dlterm"><tt class="ph tt">nFilesOpened</tt> - <a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__context__metrics_kind_counter">Counter</a></dt>

    <dd class="dd">

<p class="p">The number of files that are opened by the operator for reading data.
</p>

     <p class="p"/>

     </dd>

  
</dl>

</div>

<div class="section">
<p class="p splhead-1"><strong class="ph b"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__context__dependencies">Libraries</a></strong></p>

 <dl class="dl">
 
  <dt class="dt dlterm">Java operator class library
  </dt>

  <dd class="dd"/>

  <dd class="dd"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__context__dependencies__managedlibrary__libpath">Library Path</a>: <tt class="ph tt">../../impl/lib/BigData.jar, ../../impl/java/bin</tt></dd>

 
 
  <dt class="dt dlterm">apache library
  </dt>

  <dd class="dd"/>

  <dd class="dd"><a class="xref" href="OperatorModel.html#spldoc_reference_operator_model__context__dependencies__managedlibrary__libpath">Library Path</a>: <tt class="ph tt">@HADOOP_HOME@/../hadoop-conf, @HADOOP_HOME@/etc/hadoop, @HADOOP_HOME@/conf, @HADOOP_HOME@/share/hadoop/hdfs/*, @HADOOP_HOME@/share/hadoop/common/*, @HADOOP_HOME@/share/hadoop/common/lib/*, @HADOOP_HOME@/lib/*, @HADOOP_HOME@/client/*, @HADOOP_HOME@/*, @HADOOP_HOME@/../hadoop-hdfs/*</tt></dd>

 
 </dl>

</div>

</div>


</body>
</html>